{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Official evaluation script for KnowledgeNet."]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Command line usage<br>\n", "------------------<br>\n", "usage: evaluator.py [-h] [-e {span_exact,span_overlap,uri}] [-c]<br>\n", "                    [-a ANALYSISPATH] [-f {1,2,3,4,5,-1}]<br>\n", "                    goldFile predictionFile<br>\n", "positional arguments:<br>\n", "  goldFile              Path of the KnowledgeNet file with the gold data<br>\n", "  predictionFile        Path of the KnowledgeNet file with the predicted data<br>\n", "optional arguments:<br>\n", "  -h, --help            show this help message and exit<br>\n", "  -e {span_exact,span_overlap,uri}<br>\n", "                        Choose the evaluation method: span-exact vs span-<br>\n", "                        overlap vs uri<br>\n", "  -c                    print raw counts of tp/fn/fp for prec/rec/F1 metrics<br>\n", "  -a ANALYSISPATH       Folder to store error analysis and results files<br>\n", "                        (default=no analysis).<br>\n", "  -f {1,2,3,4,5,-1}     folds to evaluate. Default is 4. Choose -1 to evaluate<br>\n", "                        on all the folds.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import copy\n", "import sys\n", "import json\n", "import argparse\n", "import os\n", "from collections import defaultdict\n", "import io"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#####################################################<br>\n", "these functions are used to represent a Knowledgenet document"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class KNDocument:\n", "  def __init__(self, documentId, documentText, fold, passages, source):\n", "    self.documentId = documentId\n", "    self.documentText = documentText\n", "    self.fold = fold\n", "    self.passages = passages\n", "    self.source = source"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def __hash__(self):\n", "    return hash(self.documentId)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def __eq__(self, othr):\n", "    return (self.documentId == othr.documentId)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class KNDPassage:\n", "  def __init__(self, passageId, exhaustivelyAnnotatedProperties, passageStart, passageEnd, passageText, facts):\n", "    self.passageId = passageId\n", "    self.exhaustivelyAnnotatedProperties = exhaustivelyAnnotatedProperties\n", "    self.passageStart = passageStart\n", "    self.passageEnd = passageEnd\n", "    self.passageText = passageText\n", "    self.facts = facts"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def __hash__(self):\n", "    return hash(self.passageId)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def __eq__(self, othr):\n", "    return (self.passageId == othr.passageId)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class KNDProperty:\n", "  def __init__(self, propertyId, propertyName, propertyDescription):\n", "    self.propertyId = propertyId\n", "    self.propertyName = propertyName\n", "    self.propertyDescription = propertyDescription"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def __hash__(self):\n", "    return hash(self.propertyId)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def __eq__(self, othr):\n", "    return (self.propertyId == othr.propertyId)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class KNFact:\n", "  def __init__(self, factId, propertyId, subjectStart, subjectEnd, objectStart, objectEnd, subjectUri, objectUri, subjectText, \n", "    objectText, annotatedPassage, humanReadable):\n", "    self.factId = factId\n", "    self.propertyId = propertyId\n", "    self.subjectStart = subjectStart\n", "    self.subjectEnd = subjectEnd\n", "    self.objectStart = objectStart\n", "    self.objectEnd = objectEnd\n", "    self.subjectUri = subjectUri\n", "    self.objectUri = objectUri\n", "    self.subjectText = subjectText\n", "    self.objectText = objectText\n", "    self.annotatedPassage = annotatedPassage\n", "    self.humanReadable = humanReadable"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def __hash__(self):\n", "    return hash(self.factId)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def __eq__(self, othr):\n", "    return (self.factId == othr.factId)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#####################################################<br>\n", "these functions are used to read a Knowledgenet dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Loads Knowledgenet documents"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def readKnowledgenetFile(dataset, foldToRead, propertiesToConsider={}):\n", "  documents = {}\n", "  properties = {}\n", "  passagesWithError = set()\n", "  \n", "  reader = io.open(dataset, \"r\")\n", "  for line in reader:\n", "    document = json.loads(line)\n", "    documentId = str(document[\"documentId\"])\n", "    documentText = document[\"documentText\"]\n", "    fold = document[\"fold\"]\n", "    \n", "    source = \"TREx\"\n", "    if \"source\" in document:\n", "      source = document[\"source\"]\n", "    if fold != foldToRead and foldToRead != -1:\n", "      continue\n", "    passages = []\n", "    for passage in document[\"passages\"]:\n", "      passageId = passage[\"passageId\"]\n", "      passageStart = passage[\"passageStart\"]\n", "      passageEnd = passage[\"passageEnd\"]\n", "      passageText = passage[\"passageText\"]\n", "      # read all the annotated properties on the passage\n", "      exhaustivelyAnnotatedProperties = []\n", "      for property in passage[\"exhaustivelyAnnotatedProperties\"]:\n", "        propertyId = property[\"propertyId\"]\n", "        propertyName = property[\"propertyName\"]\n", "        propertyDescription = property[\"propertyDescription\"]\n", "        properties[propertyId] = propertyName\n", "        knpr = KNDProperty(propertyId, propertyName, propertyDescription)\n", "        exhaustivelyAnnotatedProperties.append(knpr)\n", "      # properties will always contain something except when evaluation test-no-facts.json\n", "      # in that case we use goldProperties to get the names\n", "      if (len(properties) != 0):\n", "        propertiesToConsider = properties\n", "     \n", "      facts = []\n", "      for fact in passage[\"facts\"]:\n", "        before = len(passagesWithError)\n\n", "        # those attributes have to be present and can't be empty\n", "        subjectStart = fact[\"subjectStart\"] if (checkField(\"subjectStart\", fact) == \"\") else passagesWithError.add(passageId + \"\\t\" + checkField(\"subjectStart\", fact))\n", "        subjectEnd = fact[\"subjectEnd\"] if (checkField(\"subjectEnd\", fact) == \"\") else passagesWithError.add(passageId + \"\\t\" + checkField(\"subjectEnd\", fact))\n", "        objectStart = fact[\"objectStart\"] if (checkField(\"objectStart\", fact) == \"\") else passagesWithError.add(passageId + \"\\t\" + checkField(\"objectStart\", fact))\n", "        objectEnd = fact[\"objectEnd\"] if (checkField(\"objectEnd\", fact) == \"\") else passagesWithError.add(passageId + \"\\t\" + checkField(\"objectEnd\", fact))\n", "        \n", "        # for the property check even if it exists\n", "        propertyId = fact[\"propertyId\"] if (checkField(\"propertyId\", fact) == \"\") else passagesWithError.add(passageId + \"\\t\" + checkField(\"propertyId\", fact))\n", "        if (not propertyId in propertiesToConsider):\n", "          passagesWithError.add(passageId + \"\\t\" + \"property \" + propertyId + \" unknown\")\n", "        \n", "        # read or create an id\n", "        if \"factId\" in fact and fact[\"factId\"] != \"\":\n", "          factId = fact[\"factId\"]\n", "        else:\n", "          factId = str(documentId) + \":\" + str(subjectStart) + \":\" + str(subjectEnd) + \":\" + str(objectStart) + \":\" + str(objectEnd) + \":\" + str(propertyId)\n\n", "        # those attributes have to be present, BUT can be empty\n", "        subjectUri = fact[\"subjectUri\"] if (\"subjectUri\" in fact) else passagesWithError.add(passageId + \"\\t\" + \"subjectUri\\tmissing field\")\n", "        objectUri = fact[\"objectUri\"] if (\"objectUri\" in fact) else passagesWithError.add(passageId + \"\\t\"+ \"objectUri\\tmissing field\")\n", "        after = len(passagesWithError)\n\n", "        # skip the passage if there is an error for one fact\n", "        if (after>before):\n", "          break\n\n", "        # those attributes are built when reading, if there are not exceptions above\n", "        subjectText = fact[\"subjectText\"] if (\"subjectText\" in fact and fact[\"subjectText\"] != \"\") else documentText[subjectStart:subjectEnd]\n", "        objectText = fact[\"objectText\"] if (\"objectText\" in fact and fact[\"objectText\"] != \"\") else documentText[objectStart:objectEnd]\n", "        \n", "        # read or create annotated passage\n", "        if \"annotatedPassage\" in fact and fact[\"annotatedPassage\"] != \"\":\n", "          annotatedPassage = fact[\"annotatedPassage\"]\n", "        else:\n", "          annotatedPassage = buildAnnotatedPassage(documentText, passageStart, passageEnd, subjectStart, subjectEnd, objectStart, objectEnd)\n\n", "        # read or create human readable\n", "        if \"humanReadable\" in fact and fact[\"humanReadable\"] != \"\":\n", "          humanReadable = fact[\"humanReadable\"]\n", "        else:\n", "          humanReadable = '<%s> <%s> <%s>' % (subjectText, propertiesToConsider[propertyId], objectText)\n", "        \n", "        knf = KNFact(factId, propertyId, subjectStart, subjectEnd, objectStart, objectEnd, subjectUri, objectUri, \n", "          subjectText, objectText, annotatedPassage, humanReadable)\n", "        facts.append(knf)\n", "      \n", "      knp = KNDPassage(passageId, exhaustivelyAnnotatedProperties, passageStart, passageEnd, passageText, facts)\n", "      passages.append(knp)\n", "    \n", "    knd = KNDocument(documentId, documentText, fold, passages, source)\n", "    documents[documentId] = knd\n", "  \n", "  reader.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  if (len(passagesWithError) > 0):\n", "    print(\"ERROR - Some facts in the following passages miss necessary fields: \")\n", "    for e in passagesWithError:\n", "      print(\" --> \" + e)\n", "    sys.exit(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  return documents, properties"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def buildAnnotatedPassage(documentText, passageStart, passageEnd, subjectStart, subjectEnd, objectStart, objectEnd):\n", "  firstEntityStart = subjectStart if (subjectStart<objectStart) else objectStart\n", "  firstEntityEnd = subjectEnd if (subjectEnd<objectEnd) else objectEnd\n", "  secondEntityStart = objectStart if (subjectStart<objectStart) else subjectStart\n", "  secondEntityEnd = objectEnd if (subjectStart<objectStart) else subjectEnd\n", "  s1 = documentText[passageStart:firstEntityStart]\n", "  s2 = documentText[firstEntityStart:firstEntityEnd]\n", "  s3 = documentText[firstEntityEnd:secondEntityStart]\n", "  s4 = documentText[secondEntityStart:secondEntityEnd]\n", "  s5 = documentText[secondEntityEnd:passageEnd]\n", "  annPassage = '%s<%s>%s<%s>%s' % (s1, s2, s3, s4, s5)\n", "  return annPassage"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def checkField(attribute, knObject):\n", "  '''\n", "   Check if the attribute is empty or missing and return an error accordingly.\n", "  '''\n", "  error = \"\"\n", "  if attribute in knObject:\n", "    if knObject[attribute] == \"\":\n", "      error = attribute + \"\\tempty field\"\n", "  else:\n", "    error = attribute + \"\\tmissing field\"\n", "  return error"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#####################################################<br>\n", "these functions are used to match two facts"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def twoFactsMatch(fact1, fact2, evaluation):\n", "  '''\n", "  Establish if two facts match based on the chosen evaluation method.\n", "  '''\n", "  entityMatch = False\n", "  if evaluation == 'uri':\n", "    entityMatch = equalsByURI(fact1, fact2)\n", "  if evaluation == 'span_exact':\n", "    entityMatch = equalsBySpanExact(fact1, fact2)\n", "  if evaluation == 'span_overlap':\n", "    entityMatch = equalsBySpanOverlap(fact1, fact2)\n", "  propertyMatch = (fact1.propertyId == fact2.propertyId)\n", "  return entityMatch and propertyMatch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def overlap(start1, end1, start2, end2):\n", "  overlap = False\n", "  #invalid offsets\n", "  if(start1 >= end1 or start2 >= end2):\n", "    overlap = False\n", "  #start is inside\n", "  if((start1 >= start2 and start1 < end2)):\n", "    overlap = True\n", "  if((start2 >= start1 and start2 < end1)):\n", "    overlap = True\n", "  #end is inside\n", "  if((end1 > start2 and end1 <= end2)):\n", "    overlap = True\n", "  if((end2 > start1 and end2 <= end1)):\n", "    overlap = True\n", "  return overlap"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def equalsBySpanExact(fact1, fact2):\n", "  subjectExact = (fact1.subjectStart == fact2.subjectStart) and (fact1.subjectEnd == fact2.subjectEnd)\n", "  objectExact = (fact1.objectStart == fact2.objectStart) and (fact1.objectEnd == fact2.objectEnd)\n", "  return (subjectExact and objectExact)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def equalsBySpanOverlap(fact1, fact2):\n", "  subjectOverlap = overlap(fact1.subjectStart, fact1.subjectEnd, fact2.subjectStart, fact2.subjectEnd)\n", "  objectOverlap = overlap(fact1.objectStart, fact1.objectEnd, fact2.objectStart, fact2.objectEnd)\n", "  return (subjectOverlap and objectOverlap)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def equalsByURI(fact1, fact2):\n", "  subjectUriExact = (getWikidataId(fact1.subjectUri) == getWikidataId(fact2.subjectUri))\n", "  objectUriExact = (getWikidataId(fact1.objectUri) == getWikidataId(fact2.objectUri))\n", "  return (subjectUriExact and objectUriExact)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def getWikidataId(uri):\n", "  if uri.endswith(\"/\"):\n", "    uri = uri.rstrip(\"/\")\n", "  uri = uri.split(\"/\")[-1]\n", "  return uri"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#####################################################<br>\n", "these functions are used when evaluating facts for uri"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def filterForURIEvaluation(dataset):\n", "  '''\n", "  For Link evaluation we filter out all the facts that do not have both uri.\n", "  '''\n", "  properties = {}\n", "  for documentId in dataset:\n", "    for passage in dataset[documentId].passages:\n", "      localProperties = {}\n", "      for prop in passage.exhaustivelyAnnotatedProperties:\n", "        localProperties[prop.propertyId] = prop.propertyName\n", "      passage.facts = [ x for x in passage.facts if isValidForURI(x)]\n", "      uniqueFacts = set()\n", "      filteredFacts = []\n", "      for f in passage.facts:\n", "        if not (f.subjectUri, f.propertyId, f.objectUri) in uniqueFacts:\n", "          uniqueFacts.add((f.subjectUri, f.propertyId, f.objectUri))\n", "          properties[f.propertyId] = localProperties[f.propertyId]\n", "          filteredFacts.append(f)\n", "      passage.facts = filteredFacts\n", "  return dataset, properties"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def isValidForURI(fact):\n", "  propertiesNoUri = set([\"5\", \"15\", \"14\"])\n", "  isPropertyForUri = not fact.propertyId in propertiesNoUri\n", "  return (fact.subjectUri != \"\") and (fact.objectUri != \"\") and isPropertyForUri"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#####################################################<br>\n", "these functions are used to print results and analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def printRecap(args):\n", "  print(\"\\n ------ Experiment Recap ------ \")\n", "  print('%-30s%-15s' % (\"Fold Evaluated\", args.f if args.f != -1 else \"all\"))\n", "  print('%-30s%-15s' % (\"Method\" , args.e))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def printPredictionsMatrix(predictionsMatrix):\n", "  print(\"\\n ------ Predictions Matrix ------\")\n", "  print('%-30s%-15s%-15s%-15s' % (\"Property\" , \"TP\", \"FP\", \"FN\"))\n", "  print('%-30s%-15s%-15s%-15s' % (\"--------\" , \"--\", \"--\", \"--\"))\n", "  tp_total = 0\n", "  fp_total = 0\n", "  fn_total = 0\n", "  for p in predictionsMatrix:\n", "    values = predictionsMatrix[p]\n", "    tp_total+=predictionsMatrix[p][\"TP\"]\n", "    fp_total+=predictionsMatrix[p][\"FP\"]\n", "    fn_total+=predictionsMatrix[p][\"FN\"]\n", "    print('%-30s%-15i%-15i%-15i' % (p , values[\"TP\"], values[\"FP\"], values[\"FN\"]))\n", "  print('%-30s%-15i%-15i%-15i' % (\"#global\" , tp_total, fp_total, fn_total))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def microEvaluation(predictionsMatrix, printPM):\n", "  if printPM:\n", "    printPredictionsMatrix(predictionsMatrix)\n", "  evals = []\n", "  print(\"\\n ------ Micro Evaluation ------ \")\n", "  print('%-30s%-15s%-15s%-15s' % (\"Property\" , \"Precision\", \"Recall\", \"F1\"))\n", "  print('%-30s%-15s%-15s%-15s' % (\"--------\" , \"-----\", \"-----\", \"-----\"))\n", "  for prop in predictionsMatrix:\n", "    tp = predictionsMatrix[prop][\"TP\"]\n", "    fp = predictionsMatrix[prop][\"FP\"]\n", "    fn = predictionsMatrix[prop][\"FN\"]\n", "    precision = float(tp)/(tp+fp) if (tp+fp) else 0.0\n", "    recall = float(tp)/(tp+fn) if (tp+fn) else 0.0\n", "    f_score = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n", "    print('%-30s%-15.3f%-15.3f%-15.3f' % (prop, precision, recall, f_score))\n", "    evals.append((prop, precision, recall, f_score))\n", "  return evals"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def macroEvaluation(predictionsMatrix):\n", "  evals = []\n", "  print(\"\\n ------ Macro Evaluation ------ \")\n", "  print('%-30s%-15s%-15s%-15s' % (\"Property\" , \"Precision\", \"Recall\", \"F1\"))\n", "  print('%-30s%-15s%-15s%-15s' % (\"--------\" , \"-----\", \"-----\", \"-----\"))\n", "  tp_total = 0\n", "  fp_total = 0\n", "  fn_total = 0\n", "  for prop in predictionsMatrix:\n", "    tp_total+=predictionsMatrix[prop][\"TP\"]\n", "    fp_total+=predictionsMatrix[prop][\"FP\"]\n", "    fn_total+=predictionsMatrix[prop][\"FN\"]\n", "  precision = float(tp_total)/(tp_total+fp_total) if (tp_total+fp_total) else 0.0\n", "  recall = float(tp_total)/(tp_total+fn_total) if (tp_total+fn_total) else 0.0\n", "  f_score = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n", "  print('%-30s%-15.3f%-15.3f%-15.3f' % (\"#global\", precision, recall, f_score))\n", "  evals.append((\"#global\", precision, recall, f_score))\n", "  # += '%s\\t%f\\t%f\\t%f\\n' % (\"#global\", precision, recall, f_score)\n", "  return evals"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def writeAnalysisFile(analysis, analysisPath, evaluation):\n", "  writer = open(analysisPath + \"/analysis_\"+evaluation+\".json\", 'w')\n", "  for documentId in analysis:\n", "    writer.write(json.dumps(analysis[documentId], default=lambda o: o.__dict__))\n", "    writer.write(\"\\n\")\n", "  writer.flush()\n", "  writer.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def writeResultsFile(evals, analysisPath, evaluation):\n", "  writer = open(analysisPath + \"/results_\"+evaluation+\".tsv\", 'w')\n", "  for p in evals:\n", "    writer.write('%s\\t%f\\t%f\\t%f\\n' % (p[0], p[1], p[2], p[3]))\n", "  writer.flush()\n", "  writer.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def writeHtmlFile(analysis, analysisPath, evaluation, goldProperties):\n", "  import codecs\n", "  writer = codecs.open(analysisPath + \"/analysis_\"+evaluation+\".html\", \"w\", \"utf-8\")\n", "  writer.write(\"<HTML><HEAD><TITLE>Error analysis</TITLE>\" +\n", "    \"</HEAD><BODY style=\\\"margin:20; padding:0;\\\" BGCOLOR=\\\"FFFFFF\\\";>\\n<h2><font color=\\\"red\\\">Error analysis</font></h2>\\n\")\n", "  for documentId in analysis:\n", "    writer.write(\"<div>\")\n", "    writer.write(\"<h3> Document: \" + documentId + \"</h2>\")\n", "    writer.write(\"<span style=\\\"white-space: pre-line\\\">\" + analysis[documentId].documentText + \"</span>\")\n", "    for passage in analysis[documentId].passages:\n", "      writer.write(\"<div style=\\\"padding-top:0px;margin-top:10px;margin-left:3em;padding-left:10px;padding-right:10px;padding-bottom:10px; margin-bottom:10px; border: 1px dashed #000\\\">\")\n", "      writer.write(\"<h4> Passage: \" + passage.passageId + \"</h4>\")\n", "      writer.write(\"<h5> Annotated For: \" + ', '.join([(p.propertyName + \" (\" + p.propertyId + \")\") for p in passage.exhaustivelyAnnotatedProperties]) + \"</h5>\")\n", "      writer.write(\"<table style=\\\"width:100%; table-layout:fixed;\\\">\")\n", "      writer.write(\"<tr>\")\n", "      writer.write(\"<td style=\\\"vertical-align:top;\\\">\")\n", "      writer.write(\"<table style=\\\"width:100%;\\\">\")\n", "      writer.write(\"<tr>\")\n", "      writer.write(\"<th colspan=\\\"3\\\">True Positive</th>\")\n", "      writer.write(\"</tr>\")\n", "      for fact in passage.facts:\n", "        if fact.eval == \"TP\":\n", "          color = \"green\";\n", "          p = fact.propertyId\n", "          if evaluation == 'uri':\n", "            subject = fact.subjectText + \" (\" + str(fact.subjectStart) + \"-\" + str(fact.subjectEnd) + \")<br><a href=\" + fact.subjectUri + \">\" + getWikidataId(fact.subjectUri) + \"</a>\"\n", "            object = fact.objectText + \" (\" + str(fact.objectStart) + \"-\" + str(fact.objectEnd) + \")<br><a href=\" + fact.objectUri + \">\" + getWikidataId(fact.objectUri) + \"</a>\"\n", "          else:\n", "            subject = fact.subjectText + \" (\" + str(fact.subjectStart) + \"-\" + str(fact.subjectEnd) + \")\"\n", "            object = fact.objectText + \" (\" + str(fact.objectStart) + \"-\" + str(fact.objectEnd) + \")\"\n", "          writer.write(\"<tr><td style=\\\"border:1px dashed \"+color+\"; text-align: center; vertical-align: middle;\\\">\" + subject + \"<br>\" + \n", "            #\"<a href=\" + fact.subjectUri + \">\" + getWikidataId(fact.subjectUri) + \"</a>\" + \n", "            \"</td><td style=\\\"border:1px dashed \"+color+\"; text-align: center; vertical-align: middle;\\\">\" + p +\n", "            \"</td><td style=\\\"border:1px dashed \"+color+\"; text-align: center; vertical-align: middle;\\\">\" + object + \"<br>\" +\n", "            #\"<a href=\" + fact.objectUri + \">\" + getWikidataId(fact.objectUri) + \"</a>\" +\n", "            \"</td></tr>\")\n", "      writer.write(\"</table>\")\n", "      writer.write(\"</td>\")\n", "      \n", "      writer.write(\"<td style=\\\"vertical-align:top;\\\">\")\n", "      writer.write(\"<table style=\\\"width:100%;\\\">\")\n", "      writer.write(\"<tr>\");\n", "      writer.write(\"<th colspan=\\\"3\\\">False Negative</th>\");\n", "      writer.write(\"</tr>\");\n", "      for fact in passage.facts:\n", "        if fact.eval == \"FN\":\n", "          color = \"red\";\n", "          p = fact.propertyId\n", "          if evaluation == 'uri':\n", "            subject = fact.subjectText + \" (\" + str(fact.subjectStart) + \"-\" + str(fact.subjectEnd) + \")<br><a href=\" + fact.subjectUri + \">\" + getWikidataId(fact.subjectUri) + \"</a>\"\n", "            object = fact.objectText + \" (\" + str(fact.objectStart) + \"-\" + str(fact.objectEnd) + \")<br><a href=\" + fact.objectUri + \">\" + getWikidataId(fact.objectUri) + \"</a>\"\n", "          else:\n", "            subject = fact.subjectText + \" (\" + str(fact.subjectStart) + \"-\" + str(fact.subjectEnd) + \")\"\n", "            object = fact.objectText + \" (\" + str(fact.objectStart) + \"-\" + str(fact.objectEnd) + \")\"\n", "          writer.write(\"<tr><td style=\\\"border:1px dashed \"+color+\"; text-align: center; vertical-align: middle;\\\">\" + subject + \"<br>\" + \n", "            #\"<a href=\" + fact.subjectUri + \">\" + getWikidataId(fact.subjectUri) + \"</a>\" + \n", "            \"</td><td style=\\\"border:1px dashed \"+color+\"; text-align: center; vertical-align: middle;\\\">\" + p +\n", "            \"</td><td style=\\\"border:1px dashed \"+color+\"; text-align: center; vertical-align: middle;\\\">\" + object + \"<br>\" +\n", "            #\"<a href=\" + fact.objectUri + \">\" + getWikidataId(fact.objectUri) + \"</a>\" +  \n", "            \"</td></tr>\")\n", "      writer.write(\"</table>\")\n", "      writer.write(\"</td>\")\n", "      writer.write(\"<td style=\\\"vertical-align:top;\\\">\")\n", "      writer.write(\"<table style=\\\"width:100%;\\\">\")\n", "      writer.write(\"<tr>\");\n", "      writer.write(\"<th colspan=\\\"3\\\">False Positive</th>\");\n", "      writer.write(\"</tr>\");\n", "      for fact in passage.facts:\n", "        if fact.eval == \"FP\":\n", "          color = \"DarkMagenta\";\n", "          p = fact.propertyId\n", "          if evaluation == 'uri':\n", "            subject = fact.subjectText + \" (\" + str(fact.subjectStart) + \"-\" + str(fact.subjectEnd) + \")<br><a href=\" + fact.subjectUri + \">\" + getWikidataId(fact.subjectUri) + \"</a>\"\n", "            object = fact.objectText + \" (\" + str(fact.objectStart) + \"-\" + str(fact.objectEnd) + \")<br><a href=\" + fact.objectUri + \">\" + getWikidataId(fact.objectUri) + \"</a>\"\n", "          else:\n", "            subject = fact.subjectText + \" (\" + str(fact.subjectStart) + \"-\" + str(fact.subjectEnd) + \")\"\n", "            object = fact.objectText + \" (\" + str(fact.objectStart) + \"-\" + str(fact.objectEnd) + \")\"\n", "          writer.write(\"<tr><td style=\\\"border:1px dashed \"+color+\"; text-align: center; vertical-align: middle;\\\">\" + subject + \"<br>\" + \n", "            #\"<a href=\" + fact.subjectUri + \">\" + getWikidataId(fact.subjectUri) + \"</a>\" + \n", "            \"</td><td style=\\\"border:1px dashed \"+color+\"; text-align: center; vertical-align: middle;\\\">\" + p +\n", "            \"</td><td style=\\\"border:1px dashed \"+color+\"; text-align: center; vertical-align: middle;\\\">\" + object + \"<br>\" +\n", "            #\"<a href=\" + fact.objectUri + \">\" + getWikidataId(fact.objectUri) + \"</a>\" +  \n", "            \"</td></tr>\")\n", "      writer.write(\"</table>\")\n", "      writer.write(\"</td>\")\n", "      writer.write(\"</tr>\")\n", "      writer.write(\"</table>\")\n", "      writer.write(\"<h5> Text Passage: </h5>\")\n", "      writer.write(\"<span style=\\\"white-space: pre-line\\\">\" + passage.passageText + \"</span>\")\n", "      writer.write(\"</div>\")\n", "    writer.write(\"</div>\")\n", "    writer.write(\"<hr style=\\\"border: none;\\\">\")\n", "  writer.write(\"</BODY></HTML>\")\n", "  writer.flush()\n", "  writer.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#####################################################<br>\n", "this function represents the main evaluation algorithm"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def isFactInSet(fact1, set, evaluation):\n", "  '''\n", "  We re-iterate the list instead of using a set to ensure that the check is done with the same matching method (i.e. span, uri).\n", "  '''\n", "  exists = False\n", "  for fact2 in set:\n", "    exists = twoFactsMatch(fact1, fact2, evaluation)\n", "    if exists:\n", "      break\n", "  return exists"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate(goldDataset, predictionDataset, evaluation, goldProperties):\n", "  predictionsMatrix = defaultdict(lambda : defaultdict(lambda : 0))\n", "  predictionDataset_notMatched = copy.deepcopy(predictionDataset)\n", "  analysisDataset = copy.deepcopy(goldDataset)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  for documentId in goldDataset:\n", "    for goldPassage in goldDataset[documentId].passages:\n", "      for goldFact in goldPassage.facts:\n", "        matchedFacts = []\n", "        \n", "        if documentId in predictionDataset:\n", "          if goldPassage in predictionDataset[documentId].passages:\n", "            # find the right passage\n", "            predictionPassage = next(p for p in predictionDataset[documentId].passages if p.passageId == goldPassage.passageId)\n", "            for predictedFact in predictionPassage.facts:\n", "              if twoFactsMatch(goldFact, predictedFact, evaluation): \n", "                matchedFacts.append(predictedFact)\n", "          else:\n", "            print(\"ERROR - Can't find passage \" + goldPassage.passageId + \" in prediction file.\")\n", "            sys.exit(1)\n", "        else:\n", "          print(\"ERROR - Can't find document \" + documentId + \" in prediction file.\")\n", "          sys.exit(1)\n", "        \n", "        if len(matchedFacts) == 0:\n", "          predictionsMatrix[goldProperties[goldFact.propertyId]][\"FN\"] += 1\n", "          # FN --> add label FN in the relative fact for analysis\n", "          analysisPassage = next(p for p in analysisDataset[documentId].passages if p.passageId == goldPassage.passageId)\n", "          analysisFact = next(f for f in analysisPassage.facts if f.factId == goldFact.factId)\n", "          analysisFact.eval = \"FN\"\n", "        else:\n", "          predictionsMatrix[goldProperties[goldFact.propertyId]][\"TP\"] += 1\n", "          # update not matched facts\n", "          # do not replicate the existence check, already did above\n", "          notMatchedPassage = next(p for p in predictionDataset_notMatched[documentId].passages if p.passageId == goldPassage.passageId)\n", "          notMatchedPassage.facts = [ f for f in notMatchedPassage.facts if not isFactInSet(f, matchedFacts, evaluation)]\n", "          # TP --> add label TP in the relative fact for analysis\n", "          analysisPassage = next(p for p in analysisDataset[documentId].passages if p.passageId == goldPassage.passageId)\n", "          analysisFact = next(f for f in analysisPassage.facts if f.factId == goldFact.factId)\n", "          analysisFact.eval = \"TP\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  for documentId in predictionDataset_notMatched:\n", "    for notMatchedPassage in predictionDataset_notMatched[documentId].passages:\n", "      for notMatchedFact in notMatchedPassage.facts:\n", "        if documentId in goldDataset:\n", "          if notMatchedPassage in goldDataset[documentId].passages:\n", "            goldPassage = next(p for p in goldDataset[documentId].passages if p.passageId == notMatchedPassage.passageId)\n", "            # skip if not known property\n", "            if not notMatchedFact.propertyId in goldProperties:\n", "              continue\n", "            if notMatchedFact.propertyId in set([i.propertyId for i in goldPassage.exhaustivelyAnnotatedProperties]):\n", "              predictionsMatrix[goldProperties[notMatchedFact.propertyId]][\"FP\"] += 1\n", "          \n", "              # FP --> add facts and label them FP in the analysis\n", "              analysisPassage = next(p for p in analysisDataset[documentId].passages if p.passageId == notMatchedPassage.passageId)\n", "              analysisFact = copy.deepcopy(notMatchedFact)\n", "              analysisFact.eval = \"FP\"\n", "              analysisPassage.facts.append(analysisFact)\n", "          else:\n", "            print(\"ERROR - Passage \" + notMatchedPassage.passageId + \" is not in gold file.\")\n", "            sys.exit(1)\n", "        else:\n", "          print(\"ERROR - Document \" + documentId + \" is not in gold file.\")\n", "          sys.exit(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  return predictionsMatrix, analysisDataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#####################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "  # Parse arguments\n", "  parser = argparse.ArgumentParser()\n", "  parser.add_argument(\"goldFile\", type=str,\n", "            help=\"Path of the KnowledgeNet file with the gold data\")\n", "  parser.add_argument(\"predictionFile\", type=str,\n", "            help=\"Path of the KnowledgeNet file with the predicted data\")\n", "  parser.add_argument(\"-e\", choices=['span_exact', 'span_overlap', 'uri'], default=\"span_overlap\",\n", "            help=\"Choose the evaluation method: span-exact vs span-overlap vs uri\")\n", "  parser.add_argument(\"-c\", default=False, action=\"store_true\",\n", "            help=\"print raw counts of tp/fn/fp for prec/rec/F1 metrics\")\n", "  parser.add_argument(\"-a\", action='store', default=\"\", dest='analysisPath',\n", "                      help='Folder to store error analysis and results files (default=no analysis).')\n", "  parser.add_argument('-f', choices=[1,2,3,4,5,-1], default=4, type=int,\n", "            help='folds to evaluate. Default is 4. Choose -1 to evaluate on all the folds.')\n", "  args = parser.parse_args()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  # Read files\n", "  gold, goldProperties = readKnowledgenetFile(args.goldFile, args.f)\n", "  prediction, predictedProperties = readKnowledgenetFile(args.predictionFile, args.f, goldProperties)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  # Check validity of the two datasets and send alerts\n", "  if (len(gold) == 0):\n", "    print(\"ERROR - No documents in gold_file for fold = \" + str(args.f))\n", "  if (len(prediction) == 0):\n", "    print(\"ERROR - No documents in prediction_file for fold = \" + str(args.f))\n", "  if (len(gold) == 0 or len(prediction) == 0):\n", "    sys.exit(1)\n", "  if (len(prediction) != len(gold)):\n", "    print(\"ERROR - Some documents seem to be missing from prediction file.\")\n", "  if (goldProperties != predictedProperties):\n", "    print(\"ERROR - Some properties seem to be missing from gold file.\")\n", "  if (len(predictedProperties) == 0):\n", "    print(\"ERROR - Prediction file does not contain any prediction.\")\n", "    sys.exit(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  # Filter both datasets if uri only (and update list of properties)\n", "  if args.e == 'uri':\n", "    gold, goldProperties = filterForURIEvaluation(gold)\n", "    prediction, predictedProperties = filterForURIEvaluation(prediction)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  # Evaluate\n", "  predictionsMatrix, analysis = evaluate(gold, prediction, args.e, goldProperties)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  # Print results\n", "  print(\"RESULTS:\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  printRecap(args)\n", "  \n", "  evals = microEvaluation(predictionsMatrix, args.c)\n", "  evals.extend(macroEvaluation(predictionsMatrix))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  if args.analysisPath != \"\":\n", "    if not os.path.exists(args.analysisPath):\n", "      os.makedirs(args.analysisPath)\n", "    writeAnalysisFile(analysis, args.analysisPath, args.e)\n", "    writeHtmlFile(analysis, args.analysisPath, args.e, goldProperties)\n", "    writeResultsFile(evals, args.analysisPath, args.e)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}